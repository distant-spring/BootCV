% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Boot.Cal.R
\name{Boot.Cal}
\alias{Boot.Cal}
\title{Bootstrap Calibration}
\usage{
Boot.Cal(
  data,
  L,
  m,
  B.bt = 20,
  B.cv = 50,
  Brm.bt = 1000,
  alpha = 0.05,
  lambda0 = 0.368
)
}
\arguments{
\item{data}{data matrix of dimension nobs x nvars; each row is an observation vector.}

\item{L}{summary statistics with two inputs, train.data and test.data,
which are in the same form as data; it evaluates the performance of estimation fitted with train.data in test.data.}

\item{m}{training set size.}

\item{B.bt}{the number of bootstraps (default is 20).}

\item{B.cv}{the number of cross-validations (default is 50).}

\item{alpha}{1-confidence level (default is 0.05).}

\item{lambda0}{tuning parameter in determining the adjusted sample size of training set (default is 0.368).}
}
\value{
\item{sigma}{the bootstrap standard error of cross-validation estimator.}
\item{cutoff}{the quantile in computation of confidence interval.}
\item{factor}{inflation factor to account for the reduced sample size in bootstrapped training set.}
}
\description{
Boot.Cal implements the proposed algorithm (algorithm 3 in reference paper) with small B.bt and B.cv and returns the bootstrap standard error
of cross-validation estimator, cutoff for confidence interval and inflation factor.
}
\details{
The algorithm quickly estimates the standard error of cross-validation estimate
\deqn{\widehat{Err}^{CV}_m=\frac{1}{B_{CV}}\sum_{b=1}^{B_{CV}} L\left\{D_{test}^b, \hat{\psi}(D_{train}^b)\right\},}{}
where data \eqn{D=D_{train}^b\cup D_{test}^b} represents the b-th split in cross-validation and
summary statistics L evaluates the performance of estimation \eqn{\hat{\psi}} fitted with training set in testing set.
The adjusted sample size of training set \eqn{m_{adj}} is determined by minimizing
\eqn{(\frac{m_{adj}}{m/0.632}-1)^2+\lambda_0 (\frac{n-m}{n-m_{adj}}-1)^2.}
}
\examples{
library(lme4)

set.seed(1)
# data generation
n=90
p=10
x=matrix(rnorm(n*p), ncol=p)
beta=rnorm(p)
y=x\%*\%beta+rnorm(n)
data=cbind(y,x)

m=50 # training set size
# summary statistics
L=function(train.data,test.data){
  y=train.data[,1]
  x=train.data[,-1]
  yt=test.data[,1]
  xt=test.data[,-1]

  fit=lm(y~x)
  beta=fit$coef

  return(mean((yt-cbind(1,xt)\%*\%beta)^2))
}

boot=Boot.Cal(data,L,m)
result1=CV.confint(boot,data,L,m,method='Boot.Cal',adj=T,print=T)
result2=CV.confint(boot,data,L,m,method='Boot.Cal',adj=F,print=T)
}
